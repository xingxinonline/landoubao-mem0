# Mem0 Local Docker Deployment

This project deploys a Mem0 server with custom configurations for Zhipu AI (LLM) and ModelArk (Embeddings), connected to a remote Qdrant instance.

## Prerequisites

- Docker and Docker Compose installed.
- API Keys for Zhipu AI and ModelArk.

## Configuration

1.  Open `app/.env` and set your API keys:
    ```env
    ZHIPU_API_KEY=your_actual_key
    MODELARK_API_KEY=your_actual_key
    ```
    The Qdrant host is pre-configured to `115.190.27.17`.

## Running the Server

Run the following command in the root directory:

```bash
docker-compose up --build -d
```

The server will start at `http://localhost:8000`.

## API Endpoints

-   **POST /memories**: Add a memory with automatic language detection and language-aware fact extraction.
-   **POST /memories/search**: Search memories (supports cross-language search via vector embeddings).
-   **GET /memories**: Get all memories for a user.
-   **DELETE /memories/{memory_id}**: Delete a specific memory.
-   **DELETE /memories?user_id={user_id}**: Reset memories for a user.
-   **GET /health**: Health check with Mem0 initialization status.

### Language Support

The system automatically detects input language and extracts facts in the same language:

- **ä¸­æ–‡ (Chinese)** - è‡ªåŠ¨æå–ä¸­æ–‡äº‹å®
- **English** - Automatically extracts English facts
- **æ—¥æœ¬èª (Japanese)** - æ—¥æœ¬èªã§äº‹å®Ÿã‚’æŠ½å‡º
- **í•œêµ­ì–´ (Korean)** - í•œêµ­ì–´ë¡œ ì‚¬ì‹¤ ì¶”ì¶œ
- **Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Arabic)** - Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
- **Ğ ÑƒÑÑĞºĞ¸Ğ¹ (Russian)** - Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ñ„Ğ°ĞºÑ‚Ğ¾Ğ² Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼
- **à¹„à¸—à¸¢ (Thai)** - à¸ªà¸à¸±à¸”à¸‚à¹‰à¸­à¹€à¸—à¹‡à¸ˆà¸ˆà¸£à¸´à¸‡à¹ƒà¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢

See [MULTILINGUAL_FACTS.md](./MULTILINGUAL_FACTS.md) for detailed multilingual usage examples.

## Demo & Tests

### ğŸ¯ Multi-User Personal Assistant Demo

A comprehensive demonstration of Mem0's memory capabilities in a real-world scenario:

```bash
cd tests
uv run python test_personal_assistant.py
```

**Features**:
- 3 users (Zhang San, John, Tanaka) using different languages (Chinese, English, Japanese)
- 20+ rounds of conversation
- GLM-4-Flash LLM integration
- Demonstrates memory storage, recall, and personalization
- Shows perfect user isolation and cross-language search

See [PERSONAL_ASSISTANT_TEST.md](./PERSONAL_ASSISTANT_TEST.md) for detailed test results and analysis.

### ğŸ“ Quick Tests

```bash
cd tests

# Test Chinese fact extraction
uv run test_chinese_facts.py

# Test multilingual support
uv run test_multilingual.py

# Test all API endpoints
uv run test_api.py

# Run interactive demo
uv run demo_multilingual.py
```

## API Documentation

Visit `http://localhost:8000/docs` for the interactive Swagger UI.

## Implementation Details

-   **LLM**: Zhipu AI (`glm-4-flash-250414`) via OpenAI-compatible provider.
-   **Embedder**: ModelArk (`Qwen3-Embedding-8B`) via OpenAI-compatible provider.
-   **Vector Store**: Qdrant at `115.190.27.17:6333`.
-   **Package Management**: Uses `uv` for fast Python package management.
-   **Concurrency**: The server uses FastAPI. Blocking Mem0 calls are run in a thread pool to support concurrency.
