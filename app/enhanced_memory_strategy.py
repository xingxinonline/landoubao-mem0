#!/usr/bin/env python3
"""
å¢å¼ºå‹è®°å¿†ç®¡ç†ç­–ç•¥ - Enhanced Memory Management Strategy

æ ¸å¿ƒåˆ›æ–°ï¼š
1. æ—¶é—´è¡°å‡ + è¯­ä¹‰å¼ºåŒ– + ä¸Šä¸‹æ–‡é‡è¦æ€§ + ä¸ªä½“å·®å¼‚
2. å¢å¼ºæƒé‡å…¬å¼: W(t) = w_time(t) * S(t) * C(t) * I * U * M(t)
3. ç‰¹æ®Šæƒ…å½¢å¤„ç†ï¼šé¢‘ç¹å¼ºåŒ–ã€å¦å®šä¿®æ­£ã€å†²çªè§£å†³ã€æ‰¹é‡åˆå¹¶
4. åŒæ—¶é—´æˆ³è®¾è®¡ï¼šcreated_atï¼ˆå†å²æ„Ÿï¼‰ + last_activated_atï¼ˆæ´»è·ƒåº¦ï¼‰
5. è®°å¿†æº¯æºé“¾ï¼šå‹ç¼©åä¿ç•™åŸå§‹å¼•ç”¨
"""

from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass, field
from enum import Enum
import logging
import math

logger = logging.getLogger(__name__)


class UpdateTrigger(Enum):
    """æ›´æ–°è§¦å‘ç±»å‹"""
    PASSIVE_DECAY = "passive_decay"         # è¢«åŠ¨è¡°å‡ï¼ˆå®šæ—¶æœåŠ¡ï¼‰
    USER_MENTION = "user_mention"           # ç”¨æˆ·ä¸»åŠ¨æåŠ
    USER_NEGATION = "user_negation"         # ç”¨æˆ·å¦å®š/ä¿®æ­£
    MANUAL_EDIT = "manual_edit"             # æ‰‹åŠ¨ç¼–è¾‘
    FREQUENT_REINFORCE = "frequent_reinforce"  # é¢‘ç¹å¼ºåŒ–
    BATCH_MERGE = "batch_merge"             # æ‰¹é‡åˆå¹¶
    MULTIMODAL_UPDATE = "multimodal_update"  # è·¨æ¨¡æ€æ›´æ–°


class MemoryCategory(Enum):
    """è®°å¿†ç±»åˆ«ï¼ˆå½±å“è¡°å‡é€Ÿåº¦ï¼‰"""
    IDENTITY = "identity"           # èº«ä»½ä¿¡æ¯ï¼ˆæ…¢è¡°å‡ï¼‰
    STABLE_PREFERENCE = "stable_preference"  # ç¨³å®šåå¥½
    SHORT_PREFERENCE = "short_preference"    # çŸ­æœŸåå¥½ï¼ˆå¿«è¡°å‡ï¼‰
    EVENT = "event"                 # äº‹ä»¶
    SKILL = "skill"                 # æŠ€èƒ½
    FACT = "fact"                   # äº‹å®
    TEMPORARY = "temporary"         # ä¸´æ—¶ä¿¡æ¯


class ConflictResolution(Enum):
    """å†²çªè§£å†³ç­–ç•¥"""
    LATEST_WINS = "latest_wins"     # æœ€æ–°ä¼˜å…ˆï¼ˆè¦†ç›–æ—§è®°å¿†ï¼‰
    VERSION_KEEP = "version_keep"   # ä¿ç•™å¤šç‰ˆæœ¬ï¼ˆæ ‡è®°æ—¶é—´çº¿ï¼‰
    WEIGHT_BALANCE = "weight_balance"  # æƒé‡å¹³è¡¡ï¼ˆæ—§çš„é€æ¸è¡°å‡ï¼‰


@dataclass
class MemoryFactors:
    """è®°å¿†æƒé‡å› å­"""
    
    # åŸºç¡€æ—¶é—´æƒé‡
    time_weight: float = 1.0
    
    # è¯­ä¹‰å¼ºåŒ–å› å­ S(t)
    semantic_boost: float = 1.0
    
    # å†²çªä¿®æ­£å› å­ C(t)
    conflict_penalty: float = 1.0
    
    # ä¸Šä¸‹æ–‡é‡è¦æ€§ Iï¼ˆé™æ€ï¼‰
    importance: float = 1.0
    
    # ç”¨æˆ·ä¸ªæ€§åŒ– Uï¼ˆå½±å“è¡°å‡é€Ÿåº¦ï¼‰
    user_factor: float = 1.0
    
    # åŠ¨é‡/ä¹ æƒ¯å› å­ M(t)
    momentum: float = 1.0
    
    # ç»¼åˆæƒé‡
    total_weight: float = 1.0
    
    def calculate_total(self) -> float:
        """è®¡ç®—ç»¼åˆæƒé‡"""
        self.total_weight = (
            self.time_weight * 
            self.semantic_boost * 
            self.conflict_penalty * 
            self.importance * 
            self.user_factor * 
            self.momentum
        )
        return self.total_weight


@dataclass
class MemoryMetadata:
    """å¢å¼ºå‹è®°å¿†å…ƒæ•°æ®"""
    
    # ğŸ• åŒæ—¶é—´æˆ³è®¾è®¡
    created_at: str                          # åˆ›å»ºæ—¶é—´ï¼ˆå†å²æ„Ÿï¼‰
    last_activated_at: str                   # æœ€åæ¿€æ´»æ—¶é—´ï¼ˆæ´»è·ƒåº¦ï¼‰
    
    # è®°å¿†å±æ€§
    level: str = "full"                      # å‹ç¼©å±‚çº§
    category: MemoryCategory = MemoryCategory.TEMPORARY
    
    # æƒé‡å› å­
    factors: MemoryFactors = field(default_factory=MemoryFactors)
    
    # è¡Œä¸ºç»Ÿè®¡
    mention_count: int = 0                   # æåŠæ¬¡æ•°
    reinforce_count: int = 0                 # å¼ºåŒ–æ¬¡æ•°
    last_mention_time: Optional[str] = None  # æœ€åæåŠæ—¶é—´
    recent_mentions: List[str] = field(default_factory=list)  # è¿‘æœŸæåŠæ—¶é—´æˆ³
    
    # å†²çªä¸ä¿®æ­£
    is_negated: bool = False                 # æ˜¯å¦è¢«å¦å®š
    is_corrected: bool = False               # æ˜¯å¦è¢«ä¿®æ­£
    correction_history: List[Dict] = field(default_factory=list)  # ä¿®æ­£å†å²
    
    # æº¯æºé“¾
    source_ids: List[str] = field(default_factory=list)  # æ¥æºè®°å¿†ID
    merged_from: List[str] = field(default_factory=list)  # åˆå¹¶è‡ªå“ªäº›è®°å¿†
    compressed_from: Optional[str] = None     # å‹ç¼©è‡ªå“ªæ¡è®°å¿†
    
    # æ•æ„Ÿæ ‡è®°
    is_sensitive: bool = False               # æ˜¯å¦æ•æ„Ÿä¿¡æ¯
    sensitivity_level: int = 0               # æ•æ„Ÿçº§åˆ« 0-3
    
    # å¤šæ¨¡æ€
    modalities: List[str] = field(default_factory=list)  # åŒ…å«çš„æ¨¡æ€ ["text", "image", "audio"]
    
    # ç”Ÿå‘½å‘¨æœŸ
    is_deleted: bool = False                 # æ˜¯å¦å·²åˆ é™¤
    deletion_time: Optional[str] = None      # åˆ é™¤æ—¶é—´
    
    # å¯è§£é‡Šæ€§
    weight_change_log: List[Dict] = field(default_factory=list)  # æƒé‡å˜åŒ–æ—¥å¿—


@dataclass
class EnhancedUpdateDecision:
    """å¢å¼ºå‹æ›´æ–°å†³ç­–"""
    
    # åŸºç¡€å†³ç­–
    action: str                              # merge/create_new/keep_both/negate/batch_merge
    should_refresh_timestamp: bool
    should_upgrade_level: bool
    
    # å› å­æ›´æ–°
    semantic_boost_delta: float = 0.0       # è¯­ä¹‰å¼ºåŒ–å¢é‡
    conflict_penalty_delta: float = 0.0     # å†²çªæƒ©ç½šå¢é‡
    momentum_delta: float = 0.0             # åŠ¨é‡å¢é‡
    
    # ç‰¹æ®Šæ“ä½œ
    mark_as_negated: bool = False           # æ ‡è®°ä¸ºè¢«å¦å®š
    mark_as_corrected: bool = False         # æ ‡è®°ä¸ºè¢«ä¿®æ­£
    merge_targets: List[str] = field(default_factory=list)  # æ‰¹é‡åˆå¹¶ç›®æ ‡
    
    # å…ƒä¿¡æ¯
    reason: str = ""
    similarity_score: float = 0.0
    confidence: float = 1.0


class EnhancedMemoryStrategy:
    """å¢å¼ºå‹è®°å¿†ç­–ç•¥å¼•æ“"""
    
    # ğŸ¯ æ ¸å¿ƒå‚æ•°
    ALPHA_BASE = 0.01                        # åŸºç¡€è¡°å‡ç³»æ•°
    
    # ç›¸ä¼¼åº¦é˜ˆå€¼
    HIGH_SIMILARITY = 0.85
    MEDIUM_SIMILARITY = 0.60
    NEGATION_SIMILARITY = 0.70               # å¦å®šæ£€æµ‹é˜ˆå€¼
    
    # è¯­ä¹‰å¼ºåŒ– S(t)
    S_MAX = 0.5                              # æœ€å¤§å¼ºåŒ–å¹…åº¦
    LAMBDA_S = 0.05                          # å¼ºåŒ–è¡°å‡é€Ÿç‡
    
    # å†²çªä¿®æ­£ C(t)
    C_MIN = 0.3                              # æœ€å°å†²çªæƒ©ç½š
    LAMBDA_C = 0.01                          # æƒ©ç½šæ¢å¤é€Ÿç‡
    
    # ä¸Šä¸‹æ–‡é‡è¦æ€§ I
    IMPORTANCE_MAP = {
        MemoryCategory.IDENTITY: 1.5,
        MemoryCategory.STABLE_PREFERENCE: 1.3,
        MemoryCategory.SHORT_PREFERENCE: 0.9,
        MemoryCategory.EVENT: 1.0,
        MemoryCategory.SKILL: 1.2,
        MemoryCategory.FACT: 1.1,
        MemoryCategory.TEMPORARY: 0.8,
    }
    
    # åŠ¨é‡å› å­ M(t)
    M_COEF = 0.3                             # åŠ¨é‡ç³»æ•°
    LAMBDA_M = 0.5                           # åŠ¨é‡è¡°å‡
    RECENT_WINDOW_DAYS = 3                   # è¿‘æœŸçª—å£ï¼ˆå¤©ï¼‰
    
    # æƒé‡è¾¹ç•Œ
    WEIGHT_MIN = 0.01                        # æœ€å°æƒé‡
    WEIGHT_MAX = 2.0                         # æœ€å¤§æƒé‡
    
    # é¢‘ç¹å¼ºåŒ–æ£€æµ‹
    FREQUENT_THRESHOLD = 3                   # Næ¬¡æåŠè§†ä¸ºé¢‘ç¹
    FREQUENT_WINDOW_HOURS = 24               # æ—¶é—´çª—å£ï¼ˆå°æ—¶ï¼‰
    
    def __init__(self, user_factor: float = 1.0):
        """
        Args:
            user_factor: ç”¨æˆ·ä¸ªæ€§åŒ–å› å­ U (0.7-1.5)
                        < 1.0: é—å¿˜æ…¢
                        > 1.0: é—å¿˜å¿«
        """
        self.user_factor = user_factor
        self.logger = logging.getLogger(__name__)
    
    def calculate_time_weight(
        self,
        created_at: datetime,
        last_activated_at: datetime,
        now: Optional[datetime] = None,
        category: MemoryCategory = MemoryCategory.TEMPORARY
    ) -> float:
        """
        è®¡ç®—åŸºç¡€æ—¶é—´æƒé‡
        
        w_time(t) = 1 / (1 + Î±_effective * t)
        
        å…¶ä¸­ Î±_effective = Î±_base * U * category_factor
        """
        if now is None:
            now = datetime.now()
        
        # ä½¿ç”¨æœ€åæ¿€æ´»æ—¶é—´è®¡ç®—è¡°å‡
        delta = now - last_activated_at
        days = delta.total_seconds() / 86400
        
        # ç±»åˆ«å› å­ï¼ˆé‡è¦ç±»åˆ«è¡°å‡æ…¢ï¼‰
        category_factor = 1.0 / self.IMPORTANCE_MAP[category]
        
        # æœ‰æ•ˆè¡°å‡ç³»æ•°
        alpha_effective = self.ALPHA_BASE * self.user_factor * category_factor
        
        # æ—¶é—´æƒé‡
        w_time = 1.0 / (1.0 + alpha_effective * days)
        
        return w_time
    
    def calculate_semantic_boost(
        self,
        last_mention_time: Optional[datetime],
        now: Optional[datetime] = None
    ) -> float:
        """
        è®¡ç®—è¯­ä¹‰å¼ºåŒ–å› å­
        
        S(t) = 1 + s_max * exp(-Î»_s * Î”t)
        
        è¿‘æœŸæåŠæ—¶æš‚æ—¶æå‡ï¼Œéšæ—¶é—´æŒ‡æ•°è¡°å‡
        """
        if last_mention_time is None:
            return 1.0
        
        if now is None:
            now = datetime.now()
        
        delta = now - last_mention_time
        days = delta.total_seconds() / 86400
        
        boost = 1.0 + self.S_MAX * math.exp(-self.LAMBDA_S * days)
        
        return boost
    
    def calculate_conflict_penalty(
        self,
        is_negated: bool,
        negation_time: Optional[datetime],
        now: Optional[datetime] = None
    ) -> float:
        """
        è®¡ç®—å†²çªä¿®æ­£å› å­
        
        C(t) = c_min + (1 - c_min) * exp(-Î»_c * Î”t)
        
        è¢«å¦å®šæ—¶é™è‡³ c_minï¼Œéšåç¼“æ…¢æ¢å¤
        """
        if not is_negated:
            return 1.0
        
        if negation_time is None:
            return self.C_MIN
        
        if now is None:
            now = datetime.now()
        
        delta = now - negation_time
        days = delta.total_seconds() / 86400
        
        penalty = self.C_MIN + (1.0 - self.C_MIN) * math.exp(-self.LAMBDA_C * days)
        
        return penalty
    
    def calculate_momentum(
        self,
        recent_mentions: List[datetime],
        now: Optional[datetime] = None
    ) -> float:
        """
        è®¡ç®—åŠ¨é‡/ä¹ æƒ¯å› å­
        
        M(t) = 1 + m * (1 - exp(-Î»_m * n_recent))
        
        é˜²æ­¢çŸ­æœŸå¤šæ¬¡æåŠè¿‡åº¦æ”¾å¤§
        """
        if now is None:
            now = datetime.now()
        
        # ç»Ÿè®¡è¿‘æœŸçª—å£å†…çš„æåŠæ¬¡æ•°
        cutoff = now - timedelta(days=self.RECENT_WINDOW_DAYS)
        n_recent = sum(1 for mention_time in recent_mentions if mention_time >= cutoff)
        
        momentum = 1.0 + self.M_COEF * (1.0 - math.exp(-self.LAMBDA_M * n_recent))
        
        return momentum
    
    def calculate_enhanced_weight(
        self,
        metadata: MemoryMetadata,
        now: Optional[datetime] = None
    ) -> float:
        """
        è®¡ç®—å¢å¼ºå‹ç»¼åˆæƒé‡
        
        W(t) = w_time(t) * S(t) * C(t) * I * U * M(t)
        """
        if now is None:
            now = datetime.now()
        
        # è§£ææ—¶é—´æˆ³
        created_at = datetime.fromisoformat(metadata.created_at)
        last_activated_at = datetime.fromisoformat(metadata.last_activated_at)
        
        # åŸºç¡€æ—¶é—´æƒé‡
        w_time = self.calculate_time_weight(
            created_at, last_activated_at, now, metadata.category
        )
        
        # è¯­ä¹‰å¼ºåŒ–
        last_mention = None
        if metadata.last_mention_time:
            last_mention = datetime.fromisoformat(metadata.last_mention_time)
        s_boost = self.calculate_semantic_boost(last_mention, now)
        
        # å†²çªæƒ©ç½š
        negation_time = None
        if metadata.is_negated and metadata.correction_history:
            negation_time = datetime.fromisoformat(
                metadata.correction_history[-1]["time"]
            )
        c_penalty = self.calculate_conflict_penalty(
            metadata.is_negated, negation_time, now
        )
        
        # é‡è¦æ€§
        importance = self.IMPORTANCE_MAP[metadata.category]
        
        # åŠ¨é‡
        recent_mentions = [
            datetime.fromisoformat(ts) for ts in metadata.recent_mentions
        ]
        momentum = self.calculate_momentum(recent_mentions, now)
        
        # æ›´æ–°å› å­
        metadata.factors.time_weight = w_time
        metadata.factors.semantic_boost = s_boost
        metadata.factors.conflict_penalty = c_penalty
        metadata.factors.importance = importance
        metadata.factors.user_factor = self.user_factor
        metadata.factors.momentum = momentum
        
        # ç»¼åˆæƒé‡
        total = metadata.factors.calculate_total()
        
        # è¾¹ç•Œçº¦æŸ
        total = max(self.WEIGHT_MIN, min(total, self.WEIGHT_MAX))
        
        return total
    
    def detect_frequent_reinforce(
        self,
        recent_mentions: List[str],
        now: Optional[datetime] = None
    ) -> bool:
        """æ£€æµ‹é¢‘ç¹å¼ºåŒ–"""
        if now is None:
            now = datetime.now()
        
        cutoff = now - timedelta(hours=self.FREQUENT_WINDOW_HOURS)
        recent = [
            datetime.fromisoformat(ts) for ts in recent_mentions
            if datetime.fromisoformat(ts) >= cutoff
        ]
        
        return len(recent) >= self.FREQUENT_THRESHOLD
    
    def decide_enhanced_action(
        self,
        trigger: UpdateTrigger,
        old_memory: Dict[str, Any],
        new_content: str,
        similarity_score: float = 0.0,
        is_negation: bool = False,
        now: Optional[datetime] = None
    ) -> EnhancedUpdateDecision:
        """
        å¢å¼ºå‹å†³ç­–å¼•æ“
        
        Args:
            trigger: è§¦å‘ç±»å‹
            old_memory: æ—§è®°å¿†
            new_content: æ–°å†…å®¹
            similarity_score: è¯­ä¹‰ç›¸ä¼¼åº¦
            is_negation: æ˜¯å¦ä¸ºå¦å®š/ä¿®æ­£
            now: å½“å‰æ—¶é—´
        """
        if now is None:
            now = datetime.now()
        
        metadata = old_memory.get("metadata", {})
        
        # ğŸ§© æƒ…å†µ1ï¼šè¢«åŠ¨å‹ç¼©
        if trigger == UpdateTrigger.PASSIVE_DECAY:
            return EnhancedUpdateDecision(
                action="compress",
                should_refresh_timestamp=False,  # âœ… ä¸åˆ·æ–°
                should_upgrade_level=False,
                reason="å®šæ—¶æœåŠ¡è¢«åŠ¨å‹ç¼©ï¼Œä¿æŒåŸå§‹æ—¶é—´æˆ³"
            )
        
        # ğŸ§© æƒ…å†µ2ï¼šç”¨æˆ·å¦å®š/ä¿®æ­£
        if trigger == UpdateTrigger.USER_NEGATION or is_negation:
            return EnhancedUpdateDecision(
                action="negate",
                should_refresh_timestamp=False,  # æ—§è®°å¿†ä¸åˆ·æ–°
                should_upgrade_level=False,
                mark_as_negated=True,
                conflict_penalty_delta=-0.7,     # é™æƒ
                reason=f"ç”¨æˆ·å¦å®š/ä¿®æ­£ï¼Œæ—§è®°å¿†é™æƒï¼ˆç›¸ä¼¼åº¦{similarity_score:.2f}ï¼‰"
            )
        
        # ğŸ§© æƒ…å†µ3ï¼šé¢‘ç¹å¼ºåŒ–
        recent_mentions = metadata.get("recent_mentions", [])
        if self.detect_frequent_reinforce(recent_mentions, now):
            return EnhancedUpdateDecision(
                action="merge",
                should_refresh_timestamp=True,
                should_upgrade_level=True,
                semantic_boost_delta=0.3,        # é€‚åº¦æå‡
                momentum_delta=0.2,
                reason=f"é¢‘ç¹å¼ºåŒ–æ£€æµ‹ï¼ˆ{len(recent_mentions)}æ¬¡ï¼‰ï¼Œåˆå¹¶å¹¶é™åˆ¶è¿‡åº¦æå‡"
            )
        
        # ğŸ§© æƒ…å†µ4ï¼šé«˜ç›¸ä¼¼åº¦ â†’ åˆå¹¶æ›´æ–°
        if similarity_score >= self.HIGH_SIMILARITY:
            return EnhancedUpdateDecision(
                action="merge",
                should_refresh_timestamp=True,   # âœ… åˆ·æ–°
                should_upgrade_level=True,
                semantic_boost_delta=0.5,
                reason=f"é«˜ç›¸ä¼¼åº¦({similarity_score:.2f})ï¼Œåˆå¹¶æ›´æ–°å¹¶æ¿€æ´»"
            )
        
        # ğŸ§© æƒ…å†µ5ï¼šä¸­ç­‰ç›¸ä¼¼åº¦ â†’ ä¿ç•™åŒè½¨
        if similarity_score >= self.MEDIUM_SIMILARITY:
            return EnhancedUpdateDecision(
                action="keep_both",
                should_refresh_timestamp=False,  # æ—§çš„ä¸åˆ·æ–°
                should_upgrade_level=False,
                reason=f"ä¸­ç­‰ç›¸ä¼¼åº¦({similarity_score:.2f})ï¼Œä¿ç•™åŒè½¨"
            )
        
        # ğŸ§© æƒ…å†µ6ï¼šä½ç›¸ä¼¼åº¦ â†’ æ–°å»ºç‹¬ç«‹
        return EnhancedUpdateDecision(
            action="create_new",
            should_refresh_timestamp=False,      # æ—§çš„ä¸åˆ·æ–°
            should_upgrade_level=False,
            reason=f"ä½ç›¸ä¼¼åº¦({similarity_score:.2f})ï¼Œæ–°å»ºç‹¬ç«‹è®°å¿†"
        )
    
    def merge_memories_batch(
        self,
        memories: List[Dict[str, Any]],
        similarity_threshold: float = 0.75
    ) -> Dict[str, Any]:
        """
        æ‰¹é‡åˆå¹¶ç›¸ä¼¼è®°å¿†
        
        ç”¨äºå¤„ç†é‡å¤è®°å¿†ï¼ˆå¦‚æ¯å¤©è¯´"å–å’–å•¡"ï¼‰
        """
        if not memories:
            return {}
        
        # é€‰æ‹©æœ€æ–°çš„ä½œä¸ºåŸºå‡†
        base = max(memories, key=lambda m: m["metadata"]["last_activated_at"])
        
        merged = {
            "memory": self._summarize_batch([m["memory"] for m in memories]),
            "metadata": {
                **base["metadata"],
                "merged_from": [m["id"] for m in memories if m["id"] != base["id"]],
                "mention_count": sum(m["metadata"].get("mention_count", 1) for m in memories),
                "last_activated_at": datetime.now().isoformat()
            }
        }
        
        return merged
    
    def _summarize_batch(self, contents: List[str]) -> str:
        """æ‰¹é‡å†…å®¹æ‘˜è¦ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        # å®é™…åº”ä½¿ç”¨LLMç”Ÿæˆæ‘˜è¦
        if len(contents) == 1:
            return contents[0]
        return f"é•¿æœŸåå¥½æ‘˜è¦ï¼ˆåŸºäº{len(contents)}æ¡è®°å¿†ï¼‰"
    
    def add_weight_change_log(
        self,
        metadata: MemoryMetadata,
        old_weight: float,
        new_weight: float,
        reason: str
    ):
        """è®°å½•æƒé‡å˜åŒ–ï¼ˆå¯è§£é‡Šæ€§ï¼‰"""
        log_entry = {
            "time": datetime.now().isoformat(),
            "old_weight": round(old_weight, 4),
            "new_weight": round(new_weight, 4),
            "delta": round(new_weight - old_weight, 4),
            "reason": reason,
            "factors": {
                "time_weight": round(metadata.factors.time_weight, 4),
                "semantic_boost": round(metadata.factors.semantic_boost, 4),
                "conflict_penalty": round(metadata.factors.conflict_penalty, 4),
                "importance": round(metadata.factors.importance, 4),
                "momentum": round(metadata.factors.momentum, 4),
            }
        }
        
        metadata.weight_change_log.append(log_entry)
        
        # ä¿ç•™æœ€è¿‘50æ¡
        if len(metadata.weight_change_log) > 50:
            metadata.weight_change_log = metadata.weight_change_log[-50:]


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºç­–ç•¥å¼•æ“ï¼ˆç”¨æˆ·é—å¿˜è¾ƒæ…¢ï¼‰
    strategy = EnhancedMemoryStrategy(user_factor=0.8)
    
    # åˆ›å»ºè®°å¿†å…ƒæ•°æ®
    metadata = MemoryMetadata(
        created_at="2024-01-01T10:00:00",
        last_activated_at="2024-01-01T10:00:00",
        category=MemoryCategory.STABLE_PREFERENCE,
        recent_mentions=[]
    )
    
    # è®¡ç®—åˆå§‹æƒé‡
    weight = strategy.calculate_enhanced_weight(metadata)
    print(f"åˆå§‹æƒé‡: {weight:.4f}")
    
    # æ¨¡æ‹Ÿ30å¤©å
    now = datetime.fromisoformat("2024-01-31T10:00:00")
    weight = strategy.calculate_enhanced_weight(metadata, now)
    print(f"30å¤©åæƒé‡: {weight:.4f}")
    
    # æ¨¡æ‹Ÿç”¨æˆ·æåŠï¼ˆæ¿€æ´»ï¼‰
    metadata.last_activated_at = "2024-01-31T10:00:00"
    metadata.last_mention_time = "2024-01-31T10:00:00"
    metadata.recent_mentions.append("2024-01-31T10:00:00")
    
    weight = strategy.calculate_enhanced_weight(metadata, now)
    print(f"æ¿€æ´»åæƒé‡: {weight:.4f}")
    
    # å†³ç­–æµ‹è¯•
    decision = strategy.decide_enhanced_action(
        trigger=UpdateTrigger.USER_MENTION,
        old_memory={"metadata": metadata.__dict__},
        new_content="æˆ‘è¿˜æ˜¯å–œæ¬¢å’–å•¡",
        similarity_score=0.92
    )
    
    print(f"\nå†³ç­–: {decision.action}")
    print(f"åˆ·æ–°æ—¶é—´æˆ³: {decision.should_refresh_timestamp}")
    print(f"åŸå› : {decision.reason}")
